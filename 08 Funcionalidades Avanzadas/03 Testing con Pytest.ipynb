{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4109366e",
   "metadata": {},
   "source": [
    "# Testing con Pytest\n",
    "\n",
    "Los objetivos de aprendizaje son:\n",
    "\n",
    "1. Motivación.\n",
    "2. Uso básico de Pytest.\n",
    "3. Fixtures.\n",
    "4. Marks\n",
    "5. Parametrización\n",
    "\n",
    "\n",
    "## Motivación\n",
    "\n",
    "Durante el proceso de desarrollo es muy importante comprobar que el código que escribimos funciona. \n",
    "\n",
    "Supongamos que queremos desarrollar una función que dada una `string` la convierta a [snake_case](https://en.wikipedia.org/wiki/Snake_case)\n",
    "\n",
    "utils.py\n",
    "\n",
    "````python\n",
    "def to_snake_case(x: str) -> str:\n",
    "    return '_'.join(x.lower().split())\n",
    "````\n",
    "\n",
    "Lo siguiente será comprobar que funciona:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac8affae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hola_mundo\n",
      "curso_python\n",
      "notebook\n"
     ]
    }
   ],
   "source": [
    "from utils import to_snake_case\n",
    "\n",
    "print(to_snake_case(\"hola mundo\"))\n",
    "print(to_snake_case(\"Curso Python\"))\n",
    "print(to_snake_case(\"notebook\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b339e3ce",
   "metadata": {},
   "source": [
    "Todo correcto, pero esta forma es muy manual y para que alguien más verifique pueda verificar los resultados es necesario que entienda cuáles deben ser las entradas y salidas.\n",
    "\n",
    "Podríamos intentar lo siguiente:\n",
    "\n",
    "verificar_utils.py\n",
    "\n",
    "```python\n",
    "from utils import to_snake_case\n",
    "\n",
    "def verificar_utils():\n",
    "    \n",
    "    print(to_snake_case(\"hola mundo\") == \"hola_mundo\")\n",
    "    print(to_snake_case(\"Curso Python\") == \"curso_python\")\n",
    "    print(to_snake_case(\"notebook\") == \"notebook\")\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    verificar_utils()\n",
    "```\n",
    "\n",
    "Con el caracter `!` podemos ejecutar código de python desde consola:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0279008a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "!python verificar_utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69879355",
   "metadata": {},
   "source": [
    "Mejor, pero supongamos que alguien por accidente modifica el script.\n",
    "\n",
    "verificar_utils_2.py\n",
    "\n",
    "```python\n",
    "from utils import to_snake_case\n",
    "\n",
    "def verificar_utils():\n",
    "    \n",
    "    print(to_snake_case(2) == \"hola_mundo\")\n",
    "    print(to_snake_case(\"Curso Python\") == \"curso_python\")\n",
    "    print(to_snake_case(\"notebook\") == \"notebook\")\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    verificar_utils()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c846b8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/heber.trujillo/projects/curso-python-cac/08 Funcionalidades Avanzadas/verificar_utils_2.py\", line 10, in <module>\n",
      "    verificar_utils()\n",
      "  File \"/Users/heber.trujillo/projects/curso-python-cac/08 Funcionalidades Avanzadas/verificar_utils_2.py\", line 5, in verificar_utils\n",
      "    print(to_snake_case(2) == \"hola_mundo\")\n",
      "          ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/heber.trujillo/projects/curso-python-cac/08 Funcionalidades Avanzadas/utils.py\", line 2, in to_snake_case\n",
      "    return '_'.join(x.lower().split())\n",
      "                    ^^^^^^^\n",
      "AttributeError: 'int' object has no attribute 'lower'\n"
     ]
    }
   ],
   "source": [
    "!python verificar_utils_2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdfb501",
   "metadata": {},
   "source": [
    "Ha fallado y el resto verificaciones no se han ejecutado.\n",
    "\n",
    "En este caso es fácil saber por qué a fallado, pero en bases de código más grandes en donde estamos probando muchas funciones, esta solución no es escalable.\n",
    "\n",
    "## Uso básico de Pytest.\n",
    "\n",
    "Es una herramienta que simplifica y automatiza el proceso de pruebas, aunque no es la única `Pytest` destaca entre por su facilidad de uso y su capacidad para gestionar escenarios complejos.\n",
    "\n",
    "\n",
    "Comenzaremos por reformular nuestro script verificar.\n",
    "\n",
    "test_utils.py\n",
    "\n",
    "``` python\n",
    "import pytest\n",
    "from utils import to_snake_case\n",
    "\n",
    "def test_dos_palabras():\n",
    "    assert to_snake_case(2) == \"hola_mundo\"\n",
    "\n",
    "def test_dos_palabras_mayusculas():\n",
    "    assert to_snake_case(\"Curso Python\") == \"curso_python\"\n",
    "    \n",
    "def test_una_palabra():\n",
    "    assert to_snake_case(\"notebook\") == \"notebook\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37446005",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.11.6, pytest-7.4.4, pluggy-1.3.0 -- /Users/heber.trujillo/projects/curso-python-cac/.venv/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/heber.trujillo/projects/curso-python-cac/08 Funcionalidades Avanzadas\n",
      "plugins: anyio-4.2.0\n",
      "collected 3 items                                                              \u001b[0m\n",
      "\n",
      "test_utils.py::test_dos_palabras \u001b[31mFAILED\u001b[0m\u001b[31m                                  [ 33%]\u001b[0m\n",
      "test_utils.py::test_dos_palabras_mayusculas \u001b[32mPASSED\u001b[0m\u001b[31m                       [ 66%]\u001b[0m\n",
      "test_utils.py::test_una_palabra \u001b[32mPASSED\u001b[0m\u001b[31m                                   [100%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m______________________________ test_dos_palabras _______________________________\u001b[0m\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_dos_palabras\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94massert\u001b[39;49;00m to_snake_case(\u001b[94m2\u001b[39;49;00m) == \u001b[33m\"\u001b[39;49;00m\u001b[33mhola_mundo\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_utils.py\u001b[0m:5: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "x = 2\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mto_snake_case\u001b[39;49;00m(x: \u001b[96mstr\u001b[39;49;00m) -> \u001b[96mstr\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m \u001b[33m'\u001b[39;49;00m\u001b[33m_\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.join(x.lower().split())\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       AttributeError: 'int' object has no attribute 'lower'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mutils.py\u001b[0m:2: AttributeError\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m test_utils.py::\u001b[1mtest_dos_palabras\u001b[0m - AttributeError: 'int' object has no attribute 'lower'\n",
      "\u001b[31m========================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m2 passed\u001b[0m\u001b[31m in 0.03s\u001b[0m\u001b[31m ==========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest test_utils.py -vv "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4db531",
   "metadata": {},
   "source": [
    "De esta manera podríamos refactorizar y hacer más seguro nuestro código de la siguiente forma\n",
    "\n",
    "version_2/utils.py\n",
    "```python\n",
    "def to_snake_case(x: str) -> str:\n",
    "    if not isinstance(x, str):\n",
    "        raise TypeError('El argumento x debe ser un string')\n",
    "    return '_'.join(x.lower().split())\n",
    "\n",
    "```\n",
    "\n",
    "version_2/test_utils.py\n",
    "``` python\n",
    "import pytest\n",
    "from utils import to_snake_case\n",
    "\n",
    "def test_dos_palabras():\n",
    "    assert to_snake_case(\"hola_mundo\") == \"hola_mundo\"\n",
    "\n",
    "def test_dos_palabras_mayusculas():\n",
    "    assert to_snake_case(\"Curso Python\") == \"curso_python\"\n",
    "    \n",
    "def test_una_palabra():\n",
    "    assert to_snake_case(\"notebook\") == \"notebook\"\n",
    "\n",
    "def test_raises_exception_no_string_arg():\n",
    "    with pytest.raises(TypeError):\n",
    "        to_snake_case(5)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aae0e587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.11.6, pytest-7.4.4, pluggy-1.3.0 -- /Users/heber.trujillo/projects/curso-python-cac/.venv/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/heber.trujillo/projects/curso-python-cac/08 Funcionalidades Avanzadas/version_2\n",
      "plugins: anyio-4.2.0\n",
      "collected 4 items                                                              \u001b[0m\n",
      "\n",
      "test_utils.py::test_dos_palabras \u001b[32mPASSED\u001b[0m\u001b[32m                                  [ 25%]\u001b[0m\n",
      "test_utils.py::test_dos_palabras_mayusculas \u001b[32mPASSED\u001b[0m\u001b[32m                       [ 50%]\u001b[0m\n",
      "test_utils.py::test_una_palabra \u001b[32mPASSED\u001b[0m\u001b[32m                                   [ 75%]\u001b[0m\n",
      "test_utils.py::test_raises_exception_no_string_arg \u001b[32mPASSED\u001b[0m\u001b[32m                [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m4 passed\u001b[0m\u001b[32m in 0.00s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cd version_2 && pytest -vv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5707956b",
   "metadata": {},
   "source": [
    "## Fixtures.\n",
    "\n",
    "Son una forma de proporcionar datos (dobles de pruebas) a un test, i.e configurar el estado de las pruebas.\n",
    "\n",
    "Los `fixtures` son funciones que pueden devolver una amplia gama de valores. Cada prueba que dependa de un `fixture` debe aceptar explícitamente ese `fixture` como argumento.\n",
    "\n",
    "### Cuándo crear un Fixture.\n",
    "\n",
    "Simularemos el flujo de trabajo típico de [*test-driven development*](https://en.wikipedia.org/wiki/Test-driven_development) (TDD).\n",
    "\n",
    "Imaginemos que estamos escribiendo la función `format_data_for_display()`, Esta función procesa los datos que nos regresa un `endpoint` de una API .\n",
    "\n",
    "Los datos que nos regresa la API representan una lista de personas, cada una con:\n",
    "\n",
    "- Nombre\n",
    "- Apellido\n",
    "- Cargo. \n",
    "\n",
    "La función debe generar una lista de cadenas que incluyan el nombre completo de cada persona, dos puntos y su título.\n",
    "\n",
    "version_3/utils.py\n",
    "````python\n",
    "from typing import List, Dict\n",
    "\n",
    "Personas = List[Dict[str, str]]\n",
    "\n",
    "def format_data_for_display(personas: Personas):\n",
    "    # TODO: implementar el código de la función. \n",
    "    raise NotImplementedError()\n",
    "````\n",
    "\n",
    "En TDD antes de desarrollar el código escribiremos una prueba, por ejemplo:\n",
    "\n",
    "version_3/test_format_data.py\n",
    "```` python\n",
    "from utils import format_data_for_display\n",
    "\n",
    "def test_format_data_for_display():\n",
    "    personas = [\n",
    "        {\n",
    "            \"nombre\": \"Heber\",\n",
    "            \"apellido\": \"Trujillo\",\n",
    "            \"cargo\": \"Machine Learning Enineer\",\n",
    "        },\n",
    "        {\n",
    "            \"nombre\": \"Montserrat\",\n",
    "            \"apellido\": \"Navarro\",\n",
    "            \"cargo\": \"Data Enineer\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    assert format_data_for_display(personas) == [\n",
    "        \"Heber Trujillo: Machine Learning Enineer\",\n",
    "        \"Montserrat Navarro: Data Enineer\",\n",
    "    ]\n",
    "````\n",
    "\n",
    "Supongamos que mientras escribimos este test, se nos ocurre que también podríamos necesitar escribir una función para transformar los datos en valores separados por comas para compartir los resultados en formato `*.csv`.\n",
    "\n",
    "version_3/utils.py\n",
    "````python\n",
    "from typing import List, Dict\n",
    "\n",
    "Personas = List[Dict[str, str]]\n",
    "\n",
    "def format_data_for_display(personas: Personas):\n",
    "    # TODO: implementar el código de la función. \n",
    "    raise NotImplementedError()\n",
    "\n",
    "def format_data_for_csv(personas: Personas):\n",
    "    # TODO: implementar el código de la función. \n",
    "    raise NotImplementedError()\n",
    "````\n",
    "\n",
    "> **Nota:** Una de las ventajas de TDD es que nos ayuda a planificar el trabajo que tenemos por hacer. \n",
    "\n",
    "La prueba para la función `format_data_for_csv()` se vería muy similar a la función `format_data_for_display()`, iríamos en contra del principio DRY.\n",
    "\n",
    "\n",
    "version_3/test_format_data.py\n",
    "```` python\n",
    "from utils import format_data_for_display, format_data_for_csv\n",
    "\n",
    "def test_format_data_for_display():\n",
    "    personas = [\n",
    "        {\n",
    "            \"nombre\": \"Heber\",\n",
    "            \"apellido\": \"Trujillo\",\n",
    "            \"cargo\": \"Machine Learning Enineer\",\n",
    "        },\n",
    "        {\n",
    "            \"nombre\": \"Montserrat\",\n",
    "            \"apellido\": \"Navarro\",\n",
    "            \"cargo\": \"Data Enineer\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    assert format_data_for_display(personas) == [\n",
    "        \"Heber Trujillo: Machine Learning Enineer\",\n",
    "        \"Montserrat Navarro: Data Enineer\",\n",
    "    ]\n",
    "\n",
    "def test_format_data_for_csv():\n",
    "    personas = [\n",
    "        {\n",
    "            \"nombre\": \"Heber\",\n",
    "            \"apellido\": \"Trujillo\",\n",
    "            \"cargo\": \"Machine Learning Enineer\",\n",
    "        },\n",
    "        {\n",
    "            \"nombre\": \"Montserrat\",\n",
    "            \"apellido\": \"Navarro\",\n",
    "            \"cargo\": \"Data Enineer\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    assert format_data_for_csv(personas) == \"nombre,apellido,cargo\\nHeber,Trujillo,Machine Learning Enineer\\nMontserrat,Navarro,Data Enineer\"\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d635f3f",
   "metadata": {},
   "source": [
    "Ambas pruebas tienen que repetir la definición de la variable de `personas`.\n",
    "\n",
    "Qué hacer si escribimos varias pruebas que hacen uso de los mismos datos?\n",
    "\n",
    "Podemos declarar los datos repetidos en una función decorada con `@pytest.fixture` para indicar que la función es un `fixture` de pytest:\n",
    "\n",
    "version_3/test_format_data.py\n",
    "```` python\n",
    "import pytest\n",
    "from utils import format_data_for_display, format_data_for_csv, Personas\n",
    "\n",
    "\n",
    "@pytest.fixture\n",
    "def personas() -> Personas:\n",
    "    return [\n",
    "        {\n",
    "            \"nombre\": \"Heber\",\n",
    "            \"apellido\": \"Trujillo\",\n",
    "            \"cargo\": \"Machine Learning Enineer\",\n",
    "        },\n",
    "        {\n",
    "            \"nombre\": \"Montserrat\",\n",
    "            \"apellido\": \"Navarro\",\n",
    "            \"cargo\": \"Data Enineer\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "def test_format_data_for_display(personas: Personas):\n",
    "    \n",
    "    assert format_data_for_display(personas) == [\n",
    "        \"Heber Trujillo: Machine Learning Enineer\",\n",
    "        \"Montserrat Navarro: Data Enineer\",\n",
    "    ]\n",
    "\n",
    "def test_format_data_for_csv(personas: Personas):\n",
    "    assert format_data_for_csv(personas) == \"nombre,apellido,cargo\\nHeber,Trujillo,Machine Learning Enineer\\nMontserrat,Navarro,Data Enineer\"\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6018f2a1",
   "metadata": {},
   "source": [
    "### Cuando Evitar Usar Fixtures\n",
    "\n",
    "Los `fixtures` son excelentes para extraer datos que se usan en múltiples pruebas. Sin embargo, no siempre son tan buenos para las pruebas que requieren ligeras variaciones en los datos. \n",
    "\n",
    "> Ensuciar las pruebas con `fixtures` no es mejor que ensuciarlas con datos u objetos simples. Incluso podría ser peor debido a la capa adicional de direccionamiento indirecto.\n",
    "\n",
    "\n",
    "Como ocurre con la mayoría de las abstracciones, se necesita algo de práctica y reflexión para encontrar el nivel adecuado de uso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef4a2125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.11.6, pytest-7.4.4, pluggy-1.3.0 -- /Users/heber.trujillo/projects/curso-python-cac/.venv/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/heber.trujillo/projects/curso-python-cac/08 Funcionalidades Avanzadas/version_3\n",
      "plugins: anyio-4.2.0\n",
      "collected 2 items                                                              \u001b[0m\n",
      "\n",
      "test_format_data.py::test_format_data_for_display \u001b[32mPASSED\u001b[0m\u001b[32m                 [ 50%]\u001b[0m\n",
      "test_format_data.py::test_format_data_for_csv \u001b[31mFAILED\u001b[0m\u001b[31m                     [100%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m___________________________ test_format_data_for_csv ___________________________\u001b[0m\n",
      "\n",
      "personas = [{'apellido': 'Trujillo', 'cargo': 'Machine Learning Enineer', 'nombre': 'Heber'}, {'apellido': 'Navarro', 'cargo': 'Data Enineer', 'nombre': 'Montserrat'}]\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_format_data_for_csv\u001b[39;49;00m(personas: Personas):\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94massert\u001b[39;49;00m format_data_for_csv(personas) == \u001b[33m\"\u001b[39;49;00m\u001b[33mnombre,apellido,cargo\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mHeber,Trujillo,Machine Learning Enineer\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mMontserrat,Navarro,Data Enineer\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_format_data.py\u001b[0m:28: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "personas = [{'apellido': 'Trujillo', 'cargo': 'Machine Learning Enineer', 'nombre': 'Heber'}, {'apellido': 'Navarro', 'cargo': 'Data Enineer', 'nombre': 'Montserrat'}]\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mformat_data_for_csv\u001b[39;49;00m(personas: Personas):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# TODO: implementar el código de la función.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mutils.py\u001b[0m:13: NotImplementedError\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m test_format_data.py::\u001b[1mtest_format_data_for_csv\u001b[0m - NotImplementedError\n",
      "\u001b[31m========================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m1 passed\u001b[0m\u001b[31m in 0.03s\u001b[0m\u001b[31m ==========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cd version_3 && pytest -vv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0025bded",
   "metadata": {},
   "source": [
    "### Cómo usar fixtures a escala\n",
    "\n",
    "A medida que creamos `fixtures`, es posible identificar algunos `fixtures` que podrían beneficiarse de una mayor modularización, i.e. definirlos en un común e importarlos.\n",
    "\n",
    "Por ejemplo, si dos archivos `test_*.py` comparten un mismo `fixture` podríamos mover el código duplicado a un módulo general que contenga `fixtures`. Este es un buen enfoque cuando usamos un `fixture` repetidamente a lo largo de un proyecto.\n",
    "\n",
    "`pytest` cuenta con una funcionalidad que automatiza esto, \n",
    "Si queremos que un `fixture` esté disponible en toda la suite de pruebas sin tener que importarlo en cada sitio, podemos configurar un módulo especial llamado `conftest.py`.\n",
    "\n",
    "\n",
    "version_4/test_format_data.py\n",
    "```` python\n",
    "import pytest\n",
    "from utils import format_data_for_display, format_data_for_csv, Personas\n",
    "\n",
    "def test_format_data_for_display(personas: Personas):\n",
    "    \n",
    "    assert format_data_for_display(personas) == [\n",
    "        \"Heber Trujillo: Machine Learning Enineer\",\n",
    "        \"Montserrat Navarro: Data Enineer\",\n",
    "    ]\n",
    "\n",
    "def test_format_data_for_csv(personas: Personas):\n",
    "    assert format_data_for_csv(personas) == \"nombre,apellido,cargo\\nHeber,Trujillo,Machine Learning Enineer\\nMontserrat,Navarro,Data Enineer\"\n",
    "````\n",
    "\n",
    "version_4/conftest.py\n",
    "```Python \n",
    "import pytest\n",
    "from utils import Personas\n",
    "\n",
    "@pytest.fixture\n",
    "def personas() -> Personas:\n",
    "    return [\n",
    "        {\n",
    "            \"nombre\": \"Heber\",\n",
    "            \"apellido\": \"Trujillo\",\n",
    "            \"cargo\": \"Machine Learning Enineer\",\n",
    "        },\n",
    "        {\n",
    "            \"nombre\": \"Montserrat\",\n",
    "            \"apellido\": \"Navarro\",\n",
    "            \"cargo\": \"Data Enineer\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad423fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.11.6, pytest-7.4.4, pluggy-1.3.0 -- /Users/heber.trujillo/projects/curso-python-cac/.venv/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/heber.trujillo/projects/curso-python-cac/08 Funcionalidades Avanzadas/version_4\n",
      "plugins: anyio-4.2.0\n",
      "collected 2 items                                                              \u001b[0m\n",
      "\n",
      "test_format_data.py::test_format_data_for_display \u001b[32mPASSED\u001b[0m\u001b[32m                 [ 50%]\u001b[0m\n",
      "test_format_data.py::test_format_data_for_csv \u001b[31mFAILED\u001b[0m\u001b[31m                     [100%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m___________________________ test_format_data_for_csv ___________________________\u001b[0m\n",
      "\n",
      "personas = [{'apellido': 'Trujillo', 'cargo': 'Machine Learning Enineer', 'nombre': 'Heber'}, {'apellido': 'Navarro', 'cargo': 'Data Enineer', 'nombre': 'Montserrat'}]\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_format_data_for_csv\u001b[39;49;00m(personas: Personas):\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94massert\u001b[39;49;00m format_data_for_csv(personas) == \u001b[33m\"\u001b[39;49;00m\u001b[33mnombre,apellido,cargo\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mHeber,Trujillo,Machine Learning Enineer\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mMontserrat,Navarro,Data Enineer\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_format_data.py\u001b[0m:12: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "personas = [{'apellido': 'Trujillo', 'cargo': 'Machine Learning Enineer', 'nombre': 'Heber'}, {'apellido': 'Navarro', 'cargo': 'Data Enineer', 'nombre': 'Montserrat'}]\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mformat_data_for_csv\u001b[39;49;00m(personas: Personas):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# TODO: implementar el código de la función.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mutils.py\u001b[0m:13: NotImplementedError\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m test_format_data.py::\u001b[1mtest_format_data_for_csv\u001b[0m - NotImplementedError\n",
      "\u001b[31m========================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m1 passed\u001b[0m\u001b[31m in 0.03s\u001b[0m\u001b[31m ==========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cd version_4 && pytest -vv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57757b9",
   "metadata": {},
   "source": [
    "## Marks\n",
    "\n",
    "En una siute de pruebas grande querremos evitar ejecutar todas las pruebas cuando desarrollamos una característica pequeña. \n",
    "\n",
    "Además del comportamiento predeterminado de pytest para ejecutar todas las pruebas en el directorio de trabajo actual o el parámetro `--ignore` podemos filtrar de manera más granular mediante el uso de marcdores.\n",
    "\n",
    "`pytest` nos permite definir categorías para nuestras pruebas y brinda opciones para incluir o excluir categorías cuando ejecuta la suite.\n",
    "\n",
    "Pese a que el número de marcadores es indeterminado, los valores típicos son:\n",
    "\n",
    "- unit: Pruebas unitarias, e.g. comprueban que una función de ejecuta correctamente.\n",
    "- integration: Pruebas que integran dos o más funcionalidades, e.g. una clase con varios métodos que cambian el estado de la instancia.\n",
    "- e2e: Sirven para comprobar de inicio a fin una rutina compleja.\n",
    "\n",
    "También podemos usar otros valores como `@pytest.mark.database_access` Si algunas de nuestras pruebas requieren acceso a una base de datos.\n",
    "\n",
    "version_5/test_format_data.py\n",
    "```python \n",
    "import pytest\n",
    "from utils import format_data_for_display, format_data_for_csv, Personas\n",
    "\n",
    "@pytest.mark.unit\n",
    "def test_format_data_for_display(personas: Personas):\n",
    "\n",
    "    assert format_data_for_display(personas) == [\n",
    "        \"Heber Trujillo: Machine Learning Enineer\",\n",
    "        \"Montserrat Navarro: Data Enineer\",\n",
    "    ]\n",
    "\n",
    "@pytest.mark.e2e\n",
    "def test_format_data_for_csv(personas: Personas):\n",
    "    assert format_data_for_csv(personas) == \"nombre,apellido,cargo\\nHeber,Trujillo,Machine Learning Enineer\\nMontserrat,Navarro,Data Enineer\"\n",
    "```\n",
    "\n",
    "> **PRO Tip**: Dado que podemos llamar como queramos a nuetros `marks`, es fácil escribir mal o recordar mal el nombre de un `mark`. pytest nos advertirá sobre esto. \n",
    "\n",
    "Para evitarlo podríamos:\n",
    "\n",
    "1. Añadir la configuración de inicialización de `pytest` al `project.toml`\n",
    "\n",
    "```toml\n",
    "[tool.pytest.ini_options]\n",
    "markers = [\n",
    "    \"unit: pruebas unitarias\",\n",
    "    \"e2e\",\n",
    "]\n",
    "```\n",
    "\n",
    "2. Añadir el flag `--strict-markers` a la llamada de `pytest`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d8dde78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.11.6, pytest-7.4.4, pluggy-1.3.0 -- /Users/heber.trujillo/projects/curso-python-cac/.venv/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/heber.trujillo/projects/curso-python-cac/08 Funcionalidades Avanzadas/version_5\n",
      "plugins: anyio-4.2.0\n",
      "collected 2 items / 1 deselected / 1 selected                                  \u001b[0m\n",
      "\n",
      "test_format_data.py::test_format_data_for_display \u001b[32mPASSED\u001b[0m\u001b[33m                 [100%]\u001b[0m\n",
      "\n",
      "\u001b[33m=============================== warnings summary ===============================\u001b[0m\n",
      "test_format_data.py:4\n",
      "  /Users/heber.trujillo/projects/curso-python-cac/08 Funcionalidades Avanzadas/version_5/test_format_data.py:4: PytestUnknownMarkWarning: Unknown pytest.mark.unit - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n",
      "    @pytest.mark.unit\n",
      "\n",
      "test_format_data.py:12\n",
      "  /Users/heber.trujillo/projects/curso-python-cac/08 Funcionalidades Avanzadas/version_5/test_format_data.py:12: PytestUnknownMarkWarning: Unknown pytest.mark.e2e - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n",
      "    @pytest.mark.e2e\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[33m================= \u001b[32m1 passed\u001b[0m, \u001b[33m\u001b[1m1 deselected\u001b[0m, \u001b[33m\u001b[1m2 warnings\u001b[0m\u001b[33m in 0.00s\u001b[0m\u001b[33m ==================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cd version_5 && pytest -vv -m unit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2779fd",
   "metadata": {},
   "source": [
    "## Parametrización\n",
    "\n",
    "\n",
    "Antes vimos cómo usar `fixtures` en `pytest` para reducir la duplicación de código, y como los `fixtures` no son tan útiles cuando tenemos varias pruebas con inputs ligeramente diferentes.\n",
    "\n",
    "Cuando los inputs son ligeramente distintos podemos parametrizar una sola definición de prueba y `pytest` creará variantes de la prueba con los parámetros que especifiquemos.\n",
    "\n",
    "Imaginemos que tenemos los siguientes archivos:\n",
    "\n",
    "version_6/utils.py\n",
    "```python\n",
    "import re\n",
    "\n",
    "def es_palindrome(s: str)->bool:\n",
    "    s = s.lower().replace(\" \", \"\")\n",
    "    s = re.sub(r'[^\\w\\s]', '', s)\n",
    "    return s == s[::-1]\n",
    "```\n",
    "\n",
    "version_6/test_palindrome.py\n",
    "```python\n",
    "from utils import es_palindrome\n",
    "\n",
    "def test_es_palindrome_string_vacia():\n",
    "    assert es_palindrome(\"\")\n",
    "\n",
    "def test_es_palindrome_caracter():\n",
    "    assert es_palindrome(\"a\")\n",
    "\n",
    "def test_es_palindrome_mayusculas_minusculas():\n",
    "    assert es_palindrome(\"Bob\")\n",
    "\n",
    "def test_es_palindrome_con_espacios():\n",
    "    assert es_palindrome(\"anita lava la tina\")\n",
    "\n",
    "def test_es_palindrome_con_signos():\n",
    "    assert es_palindrome(\"anita lava la tina?\")\n",
    "\n",
    "def test_no_es_palindrome():\n",
    "    assert not es_palindrome(\"abc\")\n",
    "\n",
    "def test_no_es_palindrome_por_poco():\n",
    "    assert not es_palindrome(\"abab\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b6fe4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.11.6, pytest-7.4.4, pluggy-1.3.0 -- /Users/heber.trujillo/projects/curso-python-cac/.venv/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/heber.trujillo/projects/curso-python-cac/08 Funcionalidades Avanzadas/version_6\n",
      "plugins: anyio-4.2.0\n",
      "collected 7 items                                                              \u001b[0m\n",
      "\n",
      "test_palindrome.py::test_es_palindrome_string_vacia \u001b[32mPASSED\u001b[0m\u001b[32m               [ 14%]\u001b[0m\n",
      "test_palindrome.py::test_es_palindrome_caracter \u001b[32mPASSED\u001b[0m\u001b[32m                   [ 28%]\u001b[0m\n",
      "test_palindrome.py::test_es_palindrome_mayusculas_minusculas \u001b[32mPASSED\u001b[0m\u001b[32m      [ 42%]\u001b[0m\n",
      "test_palindrome.py::test_es_palindrome_con_espacios \u001b[32mPASSED\u001b[0m\u001b[32m               [ 57%]\u001b[0m\n",
      "test_palindrome.py::test_es_palindrome_con_signos \u001b[32mPASSED\u001b[0m\u001b[32m                 [ 71%]\u001b[0m\n",
      "test_palindrome.py::test_no_es_palindrome \u001b[32mPASSED\u001b[0m\u001b[32m                         [ 85%]\u001b[0m\n",
      "test_palindrome.py::test_no_es_palindrome_por_poco \u001b[32mPASSED\u001b[0m\u001b[32m                [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m7 passed\u001b[0m\u001b[32m in 0.01s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cd version_6 && pytest -vv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a33ae4b",
   "metadata": {},
   "source": [
    "Todas las funciones tiene el patrón:\n",
    "\n",
    "```python\n",
    "def test_es_palindrome_<caso particular>():\n",
    "    assert es_palindrome(\"<caso particular>\")\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "Muy repetitivo. Puedemos usar @pytest.mark.parametrize() reducir significativamente el código de prueba:\n",
    "\n",
    "\n",
    "version_7/test_palindrome.py\n",
    "```` python\n",
    "from utils import es_palindrome\n",
    "\n",
    "@pytest.mark.parametrize(\"palindrome\", [\n",
    "    \"\",\n",
    "    \"a\",\n",
    "    \"Bob\",\n",
    "    \"anita lava la tina\",\n",
    "    \"anita lava la tina?\",\n",
    "])\n",
    "def test_es_palindrome(palindrome):\n",
    "    assert es_palindrome(palindrome)\n",
    "\n",
    "@pytest.mark.parametrize(\"no_palindrome\", [\n",
    "    \"abc\",\n",
    "    \"abab\",\n",
    "])\n",
    "def test_no_es_palindrome(no_palindrome):\n",
    "    assert not es_palindrome(no_palindrome)\n",
    "```` \n",
    "\n",
    "El primer argumento para `parametrize()` es el nombre del parámetro que usaremos para todos los posibles valores. El segundo argumento es una lista de tuplas o valores individuales que representan los valores del parámetro. Podríamos simplificar aún más la expresión\n",
    "\n",
    "version_8/test_palindrome.py\n",
    "```` python\n",
    "from utils import es_palindrome\n",
    "\n",
    "@pytest.mark.parametrize(\"palindrome, resultado_esperado\", [\n",
    "    (\"\", True),\n",
    "    (\"a\", True),\n",
    "    (\"Bob\", True),\n",
    "    (\"Never odd or even\", True),\n",
    "    (\"Do geese see God?\", True),\n",
    "    (\"abc\", False),\n",
    "    (\"abab\", False),\n",
    "])\n",
    "def test_es_palindrome(palindrome, resultado_esperado):\n",
    "    assert es_palindrome(palindrome) == resultado_esperado\n",
    "```` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a22dede8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.11.6, pytest-7.4.4, pluggy-1.3.0 -- /Users/heber.trujillo/projects/curso-python-cac/.venv/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/heber.trujillo/projects/curso-python-cac/08 Funcionalidades Avanzadas/version_7\n",
      "plugins: anyio-4.2.0\n",
      "collected 7 items                                                              \u001b[0m\n",
      "\n",
      "test_palindrome.py::test_es_palindrome[] \u001b[32mPASSED\u001b[0m\u001b[32m                          [ 14%]\u001b[0m\n",
      "test_palindrome.py::test_es_palindrome[a] \u001b[32mPASSED\u001b[0m\u001b[32m                         [ 28%]\u001b[0m\n",
      "test_palindrome.py::test_es_palindrome[Bob] \u001b[32mPASSED\u001b[0m\u001b[32m                       [ 42%]\u001b[0m\n",
      "test_palindrome.py::test_es_palindrome[anita lava la tina] \u001b[32mPASSED\u001b[0m\u001b[32m        [ 57%]\u001b[0m\n",
      "test_palindrome.py::test_es_palindrome[anita lava la tina?] \u001b[32mPASSED\u001b[0m\u001b[32m       [ 71%]\u001b[0m\n",
      "test_palindrome.py::test_no_es_palindrome[abc] \u001b[32mPASSED\u001b[0m\u001b[32m                    [ 85%]\u001b[0m\n",
      "test_palindrome.py::test_no_es_palindrome[abab] \u001b[32mPASSED\u001b[0m\u001b[32m                   [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m7 passed\u001b[0m\u001b[32m in 0.01s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cd version_7 && pytest -vv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
